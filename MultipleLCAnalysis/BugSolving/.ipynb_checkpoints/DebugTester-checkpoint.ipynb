{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# Autocorrelation to see if they are truly bimodal\n",
    "# Use the MAP for the main graph. Highest probability chain.\n",
    "# Try to run without MAP\n",
    "\n",
    "# In[1]:\n",
    "import numpy as np\n",
    "import theano.tensor as tt\n",
    "import pymc3 as pm\n",
    "from scipy import stats\n",
    "from pymc3 import Continuous\n",
    "from theano import tensor \n",
    "from pymc3 import Model, Normal, Slice\n",
    "from pymc3 import sample\n",
    "from pymc3 import traceplot\n",
    "from pymc3.distributions import Interpolated\n",
    "from theano import as_op\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import threading\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "import os\n",
    "#exp, log, sqrt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_context('notebook')\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "core_count = 20\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "ResultsTable = Table(\n",
    "                    names=(\"filename\", \"filter\",\n",
    "                           \"Amplitude_MAP\", 'Amplitude_mean', 'Amplitude_sd', 'Amplitude_hpd_3%', 'Amplitude_hpd_97%', 'Amplitude_mcse_mean', 'Amplitude_mcse_sd', 'Amplitude_ess_mean', 'Amplitude_ess_sd', 'Amplitude_ess_bulk', 'Amplitude_ess_tail', 'Amplitude_r_hat',\n",
    "                           'trise_MAP','trise_mean','trise_sd','trise_hpd_3%','trise_hpd_97%','trise_mcse_mean','trise_mcse_sd','trise_ess_mean','trise_ess_sd','trise_ess_bulk','trise_ess_tail','trise_r_hat',\n",
    "                           'tfall_MAP','tfall_mean','tfall_sd','tfall_hpd_3%','tfall_hpd_97%','tfall_mcse_mean','tfall_mcse_sd','tfall_ess_mean','tfall_ess_sd','tfall_ess_bulk','tfall_ess_tail','tfall_r_hat',\n",
    "                           'Beta_MAP','Beta_mean','Beta_sd','Beta_hpd_3%','Beta_hpd_97%','Beta_mcse_mean','Beta_mcse_sd','Beta_ess_mean','Beta_ess_sd','Beta_ess_bulk','Beta_ess_tail','Beta_r_hat',\n",
    "                           't0_MAP','t0_mean','t0_sd','t0_hpd_3%','t0_hpd_97%','t0_mcse_mean','t0_mcse_sd','t0_ess_mean','t0_ess_sd','t0_ess_bulk','t0_ess_tail','t0_r_hat',\n",
    "                           'gamma_MAP','gamma_mean','gamma_sd','gamma_hpd_3%','gamma_hpd_97%','gamma_mcse_mean','gamma_mcse_sd','gamma_ess_mean','gamma_ess_sd','gamma_ess_bulk','gamma_ess_tail','gamma_r_hat',\n",
    "                           'scalar_MAP','scalar_mean','scalar_sd','scalar_hpd_3%','scalar_hpd_97%','scalar_mcse_mean','scalar_mcse_sd','scalar_ess_mean','scalar_ess_sd','scalar_ess_bulk','scalar_ess_tail','scalar_r_hat',\n",
    "                    ),\n",
    "                    meta={\"name\": \"SuperNova Data Results after PyMC3 Analysis\"},\n",
    "                    dtype=(\"U64\", \"U4\",\n",
    "                           \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\",\n",
    "                           \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\",\n",
    "                           \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\",\n",
    "                           \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\",\n",
    "                           \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\",\n",
    "                           \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\",\n",
    "                           \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\", \"float32\",\n",
    "                          )\n",
    "                    )\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "def SuperNova_CurveRise_Scalar(t, A, B, t0, trise, scalar):\n",
    "    return ((A+B*(t-t0))/(1+np.exp(-(t-t0)/trise)))+scalar\n",
    "def SuperNova_CurveFall_Scalar(t, A, B, t0, gamma, trise, tfall, scalar):\n",
    "    return (A + B*((gamma+t0)-t0))*np.exp(-(t-(gamma+t0))/tfall)/(1+np.exp(-(t-t0)/trise))+scalar\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def SuperNova_CurveRise(t, A, B, t0, trise):\n",
    "    return ((A+B*(t-t0))/(1+np.exp(-(t-t0)/trise)))\n",
    "def SuperNova_CurveFall(t, A, B, t0, gamma, trise, tfall):\n",
    "    return (A + B*((gamma+t0)-t0))*np.exp(-(t-(gamma+t0))/tfall)/(1+np.exp(-(t-t0)/trise))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "def from_posteriors(param, samples):\n",
    "    smins = []\n",
    "    smaxs = []\n",
    "    for i in samples:\n",
    "        smins.append(np.min(i[param]))\n",
    "        smaxs.append(np.max(i[param]))\n",
    "    \n",
    "    smin = np.min(smins)\n",
    "    smax = np.max(smaxs)\n",
    "    width = smax - smin\n",
    "\n",
    "    x = np.linspace(smin, smax, 1000)\n",
    "    ys = []\n",
    "    for i in samples:\n",
    "        ys.append(stats.gaussian_kde(i[param])(x))\n",
    "    y = np.prod(ys, axis = 0)\n",
    "    return Interpolated(param, x, y)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "def from_posterior(param, samples):\n",
    "    smin, smax = np.min(samples[param]), np.max(samples[param])\n",
    "    width = smax - smin\n",
    "    x = np.linspace(smin, smax, 1000)\n",
    "    y = stats.gaussian_kde(samples[param])(x)\n",
    "    return Interpolated(param, x, y)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "def make_curve(param, samples):\n",
    "    smins = []\n",
    "    smaxs = []\n",
    "\n",
    "    for i in samples:\n",
    "        smins.append(np.min(i[param]))\n",
    "        smaxs.append(np.max(i[param]))\n",
    "\n",
    "    \n",
    "\n",
    "    smin = np.min(smins)\n",
    "    smax = np.max(smaxs)\n",
    "    width = smax - smin\n",
    "\n",
    "    x, step = np.linspace(smin, smax, 1000, retstep = True)\n",
    "    ys = []\n",
    "    for i in samples:\n",
    "        ys.append(stats.gaussian_kde(i[param])(x))\n",
    "    y = np.prod(ys, axis = 0)\n",
    "    y = y + np.exp(-100)\n",
    "    y_norm = y / (np.sum(y)*step)\n",
    "    return param, x, y_norm\n",
    "def make_prior(posterior_param):\n",
    "    return Interpolated(posterior_param[0],posterior_param[1],posterior_param[2])\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "def model_run(model,i,trace, iterations, core):\n",
    "    with model:\n",
    "        # 10000 posterior samples\n",
    "        trace[i] = pm.sample(iterations, cores = core)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "path = \"/home/xjh0560/Supernova_Lightcurves/LC_Data/\"\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "def SuperNova_Analysis(file):\n",
    "# In[11]:\n",
    "    ztf_data = pd.read_hdf(file)\n",
    "    ztf_data = ztf_data.loc[ztf_data[\"programid\"] == 1]\n",
    "\n",
    "    filter_types = np.unique(ztf_data[\"filter\"])\n",
    "    filter_number = np.size(filter_types)\n",
    "\n",
    "\n",
    "    # In[12]:\n",
    "\n",
    "    #This is the test data we are going to use for a test\n",
    "    time_axis_filters = []\n",
    "    Y_observed_filter = []\n",
    "    Y_unc = []\n",
    "    scale = 10**(48.6/-2.5) * 1e23 * 1e6\n",
    "    ztf_data['jdobs'] = ztf_data['jdobs']-np.min(ztf_data['jdobs'].values)\n",
    "    end_A = np.max(ztf_data[\"jdobs\"])\n",
    "    filter_list = []\n",
    "    for i in filter_types:\n",
    "        filter_list.append(str(i).replace('\\'',''))\n",
    "        indicies = np.where(ztf_data[\"filter\"] == i)\n",
    "        time_axis_filters.append((ztf_data['jdobs'].values)[indicies])\n",
    "        \n",
    "        light_data = ((ztf_data['Fratio']).values)[indicies]\n",
    "        Y_observed_filter.append(light_data*scale)\n",
    "        \n",
    "        light_data_unc = ((ztf_data['Fratio_unc']).values)[indicies]\n",
    "        Y_unc.append(light_data_unc*scale)\n",
    "\n",
    "\n",
    "    # In[13]:\n",
    "\n",
    "    model_filters = []\n",
    "    for i in range(filter_number):\n",
    "        model_filters.append(pm.Model())\n",
    "\n",
    "\n",
    "    # In[14]:\n",
    "\n",
    "    for i in range(filter_number):\n",
    "        with model_filters[i]:\n",
    "\n",
    "            # Priors for unknown model parameters\n",
    "\n",
    "            trise = pm.Uniform('trise', lower = 0.01, upper = 50)\n",
    "            tfall = pm.Uniform('tfall', lower = 1, upper = 300)\n",
    "            \n",
    "            Amp_Guess = np.max(Y_observed_filter[i])-np.min(Y_observed_filter[i])\n",
    "            Amplitude = pm.Normal('Amplitude', mu=Amp_Guess, sigma=Amp_Guess/2)\n",
    "            \n",
    "            Beta = pm.Uniform('Beta', lower = -np.max(Y_observed_filter[i]), upper = 0)\n",
    "            \n",
    "            location_high = time_axis_filters[i][np.argmax(Y_observed_filter[i])]\n",
    "            t0 = pm.Uniform('t0', lower = 0, upper = location_high)\n",
    "            \n",
    "            sigma_est = np.sqrt(np.sum(Y_unc[i]**2))\n",
    "            sigma = pm.HalfNormal('sigma', sigma=sigma_est)\n",
    "            \n",
    "            limits = np.absolute(np.max(Y_observed_filter[i]))\n",
    "            scalar = pm.Uniform('scalar', lower = -limits, upper = limits)\n",
    "\n",
    "            #gamma = pm.Uniform('gamma', lower = np.min(time_axis), upper = np.max(time_axis), testval = (least_slope[0]-))\n",
    "            no_p = pm.Normal.dist(mu = 5, sigma = 5)\n",
    "            yes_p = pm.Normal.dist(mu = 60, sigma = 30)\n",
    "\n",
    "            gamma = pm.Mixture(\"gamma\", w=[2/3,1/3], comp_dists = [no_p, yes_p])\n",
    "            #gamma = pm.math.sum(pm.Normal(\"no_p\", mu = 5, sigma = 5),pm.Normal(\"yes_p\", mu = 60, sigma = 30))\n",
    "\n",
    "            # Expected value of outcome\n",
    "            mu_rise = SuperNova_CurveRise_Scalar(time_axis_filters[i], Amplitude, Beta, t0, trise, scalar)\n",
    "            mu_fall = SuperNova_CurveFall_Scalar(time_axis_filters[i], Amplitude, Beta, t0, gamma, trise, tfall, scalar)\n",
    "\n",
    "            mu_switch = pm.math.switch(gamma+t0 >= time_axis_filters[i], mu_rise, mu_fall)\n",
    "\n",
    "            # Likelihood (sampling distribution) of observations\n",
    "            Y_obs = pm.Normal('Y_obs', mu=mu_switch, sigma=sigma, observed=Y_observed_filter[i])\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # In[15]:\n",
    "\n",
    "    trace = []\n",
    "    print(\"First run\", file)\n",
    "    for basic_model in model_filters:\n",
    "        with basic_model:\n",
    "            # 10000 posterior samples\n",
    "            iterations = 10000\n",
    "            tune_i = int(iterations/2)\n",
    "            #start = pm.find_MAP(model=basic_model)\n",
    "            trace.append(pm.sample(iterations, tune = tune_i, cores = core_count, progressbar = False, random_seed = 10))\n",
    "\n",
    "\n",
    "    # In[16]:\n",
    "\n",
    "    counter = 0\n",
    "    for posterior in trace:\n",
    "        new_path = path+\"/lc_graphs/\"+file.split(\"/\")[-1]+\"/\"\n",
    "        if not os.path.exists(new_path):\n",
    "            os.mkdir(new_path)\n",
    "        pm.plot_posterior(posterior)[0].get_figure().savefig(new_path+\"first\"+filter_list[counter]+\".png\", dpi = 600)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "    summary_tables_all = []\n",
    "    for i in trace:\n",
    "        summary_tables_all.append(pm.summary(i))\n",
    "\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "    ess_means = []\n",
    "    for i in summary_tables_all:\n",
    "        ess_means.append(i[\"ess_mean\"].values)\n",
    "    ess_mean_max = np.max(ess_means)\n",
    "\n",
    "\n",
    "    # In[19]:\n",
    "\n",
    "    autocorlen = (iterations*core_count)/(ess_mean_max)\n",
    "\n",
    "\n",
    "    # In[20]:\n",
    "\n",
    "    combined_model = []\n",
    "    for i in range(filter_number):\n",
    "        combined_model.append(pm.Model())\n",
    "\n",
    "\n",
    "    # In[21]:\n",
    "\n",
    "    t0_posterior = make_curve(\"t0\", trace)\n",
    "\n",
    "    gamma_posterior = make_curve(\"gamma\", trace)\n",
    "\n",
    "\n",
    "    # In[22]:\n",
    "\n",
    "    for i in range(filter_number):\n",
    "        with combined_model[i]:\n",
    "            trise = pm.Uniform('trise', lower = 0.01, upper = 50)\n",
    "            \n",
    "            tfall = pm.Uniform('tfall', lower = 1, upper = 300)\n",
    "            \n",
    "            Amp_Guess = np.max(Y_observed_filter[i])-np.min(Y_observed_filter[i])\n",
    "            Amplitude = pm.Normal('Amplitude', mu=Amp_Guess, sigma=Amp_Guess/2)\n",
    "\n",
    "            Beta = pm.Uniform('Beta', lower = -np.max(Y_observed_filter[i]), upper = 0)\n",
    "\n",
    "            t0 = make_prior(t0_posterior)\n",
    "\n",
    "            sigma_est = np.sqrt(np.sum(Y_unc[i]**2))\n",
    "            sigma = pm.HalfNormal('sigma', sigma=sigma_est)\n",
    "\n",
    "            gamma = make_prior(gamma_posterior)\n",
    "            \n",
    "            limits = np.absolute(np.max(Y_observed_filter[i]))\n",
    "            scalar = pm.Uniform('scalar', lower = -limits, upper = limits)\n",
    "\n",
    "            # Expected value of outcome\n",
    "            mu_rise = SuperNova_CurveRise_Scalar(time_axis_filters[i], Amplitude, Beta, t0, trise, scalar)\n",
    "            mu_fall = SuperNova_CurveFall_Scalar(time_axis_filters[i], Amplitude, Beta, t0, gamma, trise, tfall, scalar)\n",
    "\n",
    "            mu_switch = pm.math.switch(gamma+t0 >= time_axis_filters[i], mu_rise, mu_fall)\n",
    "\n",
    "            # Likelihood (sampling distribution) of observations\n",
    "            Y_obs = pm.Normal('Y_obs', mu=mu_switch, sigma=sigma, observed=Y_observed_filter[i])\n",
    "\n",
    "\n",
    "    # In[23]:\n",
    "\n",
    "    trace_all = []\n",
    "    print(\"Second run\", file)\n",
    "    for basic_model in combined_model:\n",
    "        with basic_model:\n",
    "            # 10000 posterior samples\n",
    "            iterations = autocorlen * 100\n",
    "            if(iterations < 5000): iterations = 5000\n",
    "            tune_i = int(iterations/2)\n",
    "            #start = pm.find_MAP(model=basic_model)\n",
    "            trace_all.append(pm.sample(iterations, tune = tune_i, cores = core_count, progressbar = False, random_seed = 10))\n",
    "\n",
    "\n",
    "    # In[24]:\n",
    "\n",
    "    counter = 0\n",
    "    for posterior in trace_all:\n",
    "        new_path = path+\"/lc_graphs/\"+file.split(\"/\")[-1]+\"/\"\n",
    "        if not os.path.exists(new_path):\n",
    "            os.mkdir(new_path)\n",
    "        pm.traceplot(posterior)[0][0].get_figure().savefig(new_path+\"second\"+filter_list[counter]+\".png\", dpi = 600)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "    # In[25]:\n",
    "\n",
    "    summary_tables = []\n",
    "    for i in trace_all:\n",
    "        summary_tables.append(pm.summary(i))\n",
    "\n",
    "\n",
    "    # In[26]:\n",
    "\n",
    "    lnp = []\n",
    "    for j in range(len(trace_all)):\n",
    "        logp = combined_model[0].logp\n",
    "        lnp.append(np.array([logp(trace_all[j].point(i,chain=c)) for c in trace_all[j].chains for i in range(len(trace_all[j]))]))\n",
    "\n",
    "\n",
    "    # In[27]:\n",
    "\n",
    "    trise_R = []\n",
    "    tfall_R = []\n",
    "    Amplitude_R = []\n",
    "    Beta_R = []\n",
    "    t0_R = []\n",
    "    gamma_R = []\n",
    "    scalar_R = []\n",
    "    for i in range(len(trace_all)):\n",
    "        index = np.argmax(lnp[i])\n",
    "        trise_R.append(trace_all[i].get_values(\"trise\")[index])\n",
    "        tfall_R.append(trace_all[i].get_values(\"tfall\")[index])\n",
    "        Amplitude_R.append(trace_all[i].get_values(\"Amplitude\")[index])\n",
    "        Beta_R.append(trace_all[i].get_values(\"Beta\")[index])\n",
    "        t0_R.append(trace_all[i].get_values(\"t0\")[index])\n",
    "        gamma_R.append(trace_all[i].get_values(\"gamma\")[index])\n",
    "        scalar_R.append(trace_all[i].get_values(\"scalar\")[index])\n",
    "\n",
    "\n",
    "    # In[28]:\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    colours = [\"green\", \"red\"]\n",
    "\n",
    "    for i in range(filter_number):\n",
    "        big_time_axis_rise = np.linspace(0,t0_R[i]+gamma_R[i],num = 100)\n",
    "        ax.plot(big_time_axis_rise, SuperNova_CurveRise_Scalar(big_time_axis_rise, Amplitude_R[i], Beta_R[i], t0_R[i], trise_R[i], scalar_R[i]), color = colours[i])\n",
    "\n",
    "    for i in range(filter_number):\n",
    "        big_time_axis_fall = np.linspace(t0_R[i]+gamma_R[i],end_A,num = 100)\n",
    "        ax.plot(big_time_axis_fall, SuperNova_CurveFall_Scalar(big_time_axis_fall, Amplitude_R[i], Beta_R[i], t0_R[i], gamma_R[i], trise_R[i], tfall_R[i], scalar_R[i]), color = colours[i])\n",
    "\n",
    "    for i in range(filter_number):\n",
    "        ax.errorbar(time_axis_filters[i], Y_observed_filter[i], Y_unc[i], fmt = \"o\", color = colours[i])\n",
    "        \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y_observed')\n",
    "    fig.savefig(new_path+\"final.png\", dpi = 600)\n",
    "\n",
    "\n",
    "    # In[29]:\n",
    "\n",
    "    for i in range(len(filter_list)):\n",
    "        row = [file.split(\"/\")[-1],filter_list[i]]\n",
    "        \n",
    "        row.append(Amplitude_R[i])\n",
    "        row.extend(summary_tables[i].iloc[0].values)\n",
    "        \n",
    "        row.append(trise_R[i])\n",
    "        row.extend(summary_tables[i].iloc[1].values)\n",
    "        \n",
    "        row.append(tfall_R[i])\n",
    "        row.extend(summary_tables[i].iloc[2].values)\n",
    "        \n",
    "        row.append(Beta_R[i])\n",
    "        row.extend(summary_tables[i].iloc[3].values)\n",
    "        \n",
    "        row.append(t0_R[i])\n",
    "        row.extend(summary_tables[i].iloc[4].values)\n",
    "        \n",
    "        row.append(gamma_R[i])\n",
    "        row.extend(summary_tables[i].iloc[6].values)\n",
    "        \n",
    "        row.append(scalar_R[i])\n",
    "        row.extend(summary_tables[i].iloc[7].values)\n",
    "        \n",
    "        ResultsTable.add_row(row)\n",
    "\n",
    "\n",
    "    # In[30]:\n",
    "    new_path = path+\"/lc_graphs/\"+file.split(\"/\")[-1]+\"/\"\n",
    "    ResultsTable.write(new_path + \"/Results.csv\", overwrite = True)\n",
    "\n",
    "def run_analysis_multi(filelist):\n",
    "    for file in filelist:\n",
    "        try:\n",
    "            SuperNova_Analysis(file)\n",
    "        except:\n",
    "            print(\"File Failed \" + file)\n",
    "\n",
    "def run_analysis(file):\n",
    "    try:\n",
    "        SuperNova_Analysis(file)\n",
    "    except:\n",
    "        print(\"File Failed \" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/home/xjh0560/Supernova_Lightcurves/LC_Data/sample_lc_v2/ZTF18abfhaji_force_phot.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
